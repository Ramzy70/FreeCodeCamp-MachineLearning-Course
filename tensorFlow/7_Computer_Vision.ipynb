{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMTHsCdAiA8poIp/pTiWF9k",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ramzy70/FreeCodeCamp-MachineLearning-Course/blob/main/tensorFlow/7_Computer_Vision.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://colab.research.google.com/drive/1ZZXnCjFEOkp_KdNcNabd14yok0BAIuwS#forceEdit=true&sandboxMode=true&scrollTo=xqLsm2XzNQSE"
      ],
      "metadata": {
        "id": "C61SaGXjjOE9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "we will consider here is classifying 10 different everyday objects. The dataset we will use is built into tensorflow and called the CIFAR Image Dataset. It contains 60,000 32x32 color images with 6000 images of each class.\n",
        "\n",
        "The labels in this dataset are the following:\n",
        "\n",
        "Airplane\n",
        "Automobile\n",
        "Bird\n",
        "Cat\n",
        "Deer\n",
        "Dog\n",
        "Frog\n",
        "Horse\n",
        "Ship\n",
        "Truck"
      ],
      "metadata": {
        "id": "n0b0usYQjUHZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IpYSySK3jKu7",
        "outputId": "147153ba-57f1-474f-8803-8740a2795064"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n"
          ]
        }
      ],
      "source": [
        "%tensorflow_version 2.x  # this line is not required unless you are in a notebook\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  LOAD AND SPLIT DATASET\n",
        "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
        "\n",
        "# Normalize pixel values to be between 0 and 1\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
        "\n",
        "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "               'dog', 'frog', 'horse', 'ship', 'truck']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h7thTL3AjdII",
        "outputId": "885a0894-2a41-49e1-f8f1-55b741f937aa"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 5s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's look at a one image\n",
        "IMG_INDEX = 5555  # change this to look at other images\n",
        "\n",
        "plt.imshow(train_images[IMG_INDEX] ,cmap=plt.cm.binary)\n",
        "plt.xlabel(class_names[train_labels[IMG_INDEX][0]])\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "9vx9-3sGji5Y",
        "outputId": "185e1bc5-d85e-4943-a558-26cbc918d617"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGwCAYAAADv4LHCAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAyjElEQVR4nO3de3TU9Z3/8dfMZGZyn5CE3CRQ8IJX6JYqTb0sVRToWQ4qx9W2e8SuBw9u9FTZ2spuq7W7Pbi6a217EPfsumLPVm3tKbp6qlaxxK0LbkE51FZZYWlBSYJEcptk7t/fHy7pLwr6eUPCJ4nPxzlzDsm8eefzvcy8M5OZ14SCIAgEAMBxFva9AADAxxMDCADgBQMIAOAFAwgA4AUDCADgBQMIAOAFAwgA4EWR7wW8X6FQ0L59+1RRUaFQKOR7OQAAoyAI1NfXp6amJoXDR36cM+YG0L59+9Tc3Ox7GQCAY7R3715NmTLliNePuQFUUVEhSTpPpSqS2yOgUMj9mcRIJGJaz4dN7w/0Nj5gKzKEUBQFBVPvqGGfBIZaSYoGtg0NFdy380CF7fgUYqXOtfWTa029KyJR59rePe2m3vlczlRfGM3AkoL7uRXksqbWYcOyI8ZNDDveP0hSOG/b3znZbm/JmPttKFVkO8dzhqXkjLfNmOG2Gc+678NsEOhZ9Qzdnx/JqA2gNWvW6O6771ZHR4dmz56tH/zgBzrnnHM+8v8detqtSCEVOT4FZ3mqLmJ8Wi9iGW7WAWQ4yV2H8SFRw3ZaB1DMuJZQyP0ktwxOSSoYfkGIRWyne9xQHzOsQ5Ly1u3U6A0gy32W9Vyx3NXa7paNA8i47rBxf2cM/a3H3nZzs95PWG6bxju44KPvm0flRQg//vGPtXLlSt1+++165ZVXNHv2bC1YsED79+8fjR8HABiHRmUA3XPPPVq+fLm+/OUv6/TTT9f999+v0tJS/du//dto/DgAwDg04gMok8lo69atmj9//h9/SDis+fPna9OmTR+oT6fT6u3tHXYBAEx8Iz6ADhw4oHw+r/r6+mHfr6+vV0dHxwfqV69erUQiMXThFXAA8PHg/Y2oq1atUk9Pz9Bl7969vpcEADgORvxVcLW1tYpEIurs7Bz2/c7OTjU0NHygPh6PKx6Pj/QyAABj3Ig/AorFYpozZ442bNgw9L1CoaANGzaopaVlpH8cAGCcGpX3Aa1cuVLLli3Tpz/9aZ1zzjm69957lUwm9eUvf3k0fhwAYBwalQF05ZVX6p133tFtt92mjo4OffKTn9QzzzzzgRcmAAA+vkJBMJoZH3a9vb1KJBKar3JFHd/VWzC8QzdUZJy5hjf/loRs7+WO5fLuxWFbNEi8pNi5Nmd8g3MoY4s1Kc+775eBEtti0iH3aJgTTj7F1Lu2aZpz7Ru/2WHqHTOeh4MDSefaZNK9VrLF/BRSg6beJYY0CUtk03uLcb9NxKytjdE9fTH3c7yvLGbqnSwypCzkbfcTZVn3HVOecr+t5YKCnk93qaenR5WVlUes8/4qOADAxxMDCADgBQMIAOAFAwgA4AUDCADgBQMIAOAFAwgA4AUDCADgBQMIAOAFAwgA4MWoZMGNhEAh54idnGWMRm1RL9moe/Nwwda7pODeOyRblki4yD3uY3Kze+SMJPX09pjqBw/2O9dWTpls6t2V6XOuPRi2HZ/ainLn2nTMdlMqOcGYi5hxj8DpbW83tY7H3D8OJcikTb1ThtpoyPb7cC6Vca7NBraImkLauJ1p95iaTN52W84b7oNChugjSQoMkUOBIWkscNzfPAICAHjBAAIAeMEAAgB4wQACAHjBAAIAeMEAAgB4wQACAHjBAAIAeMEAAgB4wQACAHjBAAIAeDFms+BCCikst+yufMR9juaLbJucKTHU2yKeFA+551OVZGy/K2Tdo6kUrkiYep/yJ7NN9btf3+lcG5tcbepdnB9wrh005pgFlZXOtdHqKlPvYmN9kC11ri23HHxJVVXux/9AV5epd06Gc7yszNTbPe1QKhTcM88kKT3gfl5JUpEh77CoO2nqXRcqdq4tNeRLSlJ+sNe5tijjvg9ds/d4BAQA8IIBBADwggEEAPCCAQQA8IIBBADwggEEAPCCAQQA8IIBBADwggEEAPCCAQQA8GLMRvHEQyFFQ25RPKmQYY6GbJscVdTQ2z12RJKyJe5hIvW17rEwklRS7B5rkrX+GlJji+454/MXO9e2//4tU++qkHvsTNGAe1yKJIUTVc61dafNNPUujkVM9b3t+5xryydNMvUORd1vE6VltmOvgns+VUl5iam15WY/mLZF6+SNuVrhsPvxLMmbWiv0rvt5GzbGMMUyhvrAsPDAbf/xCAgA4AUDCADgBQMIAOAFAwgA4AUDCADgBQMIAOAFAwgA4AUDCADgBQMIAOAFAwgA4AUDCADgxZjNghssyinrmAWXDbvnNsULKdM6ijM559pSWwyTSvLu+VFBha13rtb9PyROaDL1DsfipvqyKve1TD/1RFPvPfv2OteWVrjn40lSvKTYuba2oc7UO2LMGus8sN+5tsgxh+uQcJH7eVjX1GjqXVLsnu+WMea1dXa65+MFmYypdyTlfruXpFTOvb5QbLvbjU92z98bOHDA1DuUd893izneH0tSNpDksMt5BAQA8GLEB9C3vvUthUKhYZdTTz11pH8MAGCcG5Wn4M444ww9//zzf/whRWP2mT4AgCejMhmKiorU0NAwGq0BABPEqPwN6M0331RTU5NmzJihL33pS9qzZ88Ra9PptHp7e4ddAAAT34gPoLlz52rdunV65plntHbtWu3evVvnn3+++vr6Dlu/evVqJRKJoUtzc/NILwkAMAaN+ABatGiRrrjiCs2aNUsLFizQz3/+c3V3d+snP/nJYetXrVqlnp6eocveve4vqwUAjF+j/uqAqqoqnXLKKdq5c+dhr4/H44rHbe8rAQCMf6P+PqD+/n7t2rVLjY22N7ABACa2ER9AX/3qV9XW1qbf//73+q//+i9ddtllikQi+sIXvjDSPwoAMI6N+FNwb731lr7whS+oq6tLkydP1nnnnafNmzdr8uTJpj4DRVKRY/JDJhJ17htXwbSOyIB7PEiQt+3OyOR659qKk2wRNdFG95fBRyvcoz4kqabRfd2SVFVb5VybSadNvcsHepxrUylb71DU/XiWxMpNvZWz5TZV1VQ712aztt7hkPvvoTV1tmNfWVHpXLvz9d+Zelu2Mz84aOudse3DSNz9PihSbvu9P5Rzj1bKpG1/zhgsuO+XcvfUHuUc46BGfAA9+uijI90SADABkQUHAPCCAQQA8IIBBADwggEEAPCCAQQA8IIBBADwggEEAPCCAQQA8IIBBADwggEEAPBi1D+O4WgVgrgKjvMxFS517htTyrSOUsc8OkmqOMWW1/bpK5c61572qXNMvRVEnEv3drxtal0UNewUSeVV7jlpsZIaU+9Q1D2D643Xd5h6p/LueWANdXWm3vmsLZeuatA9C849Oew90SL3u4GKatvxiRW5H5+SijJT76ghqy9a5n4fIUnxStvv5paEyXRvv6l3X1+3c20mbsyZq6lwrs31uOfG5YKC5FDOIyAAgBcMIACAFwwgAIAXDCAAgBcMIACAFwwgAIAXDCAAgBcMIACAFwwgAIAXDCAAgBdjNopH+UAKuQVc5PM557bZIluMTK7CPUYmMfMkU+9CpXv0SDKfMfWedsI059qGGU2m3l0HOk31A8ke59pqw/6WpLKpMefadLLX1Lu7x33dVZW2qJdI2BY7kxq0xbdYVFdPcq7NZC2hM1Io5P47bjbnfjuWJEXdj33YUCtJQWALNCo19E/Ebed4V979Puvd3gOm3pHSuHNtNuW+T3IFt/OER0AAAC8YQAAALxhAAAAvGEAAAC8YQAAALxhAAAAvGEAAAC8YQAAALxhAAAAvGEAAAC8YQAAAL8ZsFlxxIaeikFsGUq6Qde4bzdmyrJSodC6NlBSbWlvSqVLJPlPvt9r3ONfW1NWaek+alDDVx8LuGVKpXtt2ptNp59raatu6y0rcj1BleYmpd8ExK+uQSVXu52HOmqkWuK+lKGzLUsxm3G+bzc3Npt6NjY3u60jbshT3t3eY6vu73XMDBwZsuX5ZQy5dkLdl2KWT7vslZ+idL7jV8ggIAOAFAwgA4AUDCADgBQMIAOAFAwgA4AUDCADgBQMIAOAFAwgA4AUDCADgBQMIAOAFAwgA4MUYzoLLK+qYBaece55RRBHTOmoS1c61n/z0p0y9G2ee7FybMUbYBY5ZTJKUSqVMvQuG/f3ef3BffMGQe2WtLymx5bWVlpY61xYX23IA8/m8qX7y5MnOtclk0tTbkqeXN2YplpWVOdcWFdnujix5etb9HXK97/k/GcM+HBgYMPVOZ91vb8a7CclwPxGNRp1rQ47HhkdAAAAvzAPoxRdf1OLFi9XU1KRQKKTHH3982PVBEOi2225TY2OjSkpKNH/+fL355psjtV4AwARhHkDJZFKzZ8/WmjVrDnv9XXfdpe9///u6//779fLLL6usrEwLFiwwP80DAJjYzH8DWrRokRYtWnTY64Ig0L333qtvfOMbWrJkiSTphz/8oerr6/X444/rqquu+sD/SafTw56D7u3ttS4JADAOjejfgHbv3q2Ojg7Nnz9/6HuJREJz587Vpk2bDvt/Vq9erUQiMXSxfigVAGB8GtEB1NHx3qcI1tfXD/t+fX390HXvt2rVKvX09Axd9u7dO5JLAgCMUd5fhh2PxxWPx30vAwBwnI3oI6CGhgZJUmdn57Dvd3Z2Dl0HAIA0wgNo+vTpamho0IYNG4a+19vbq5dfflktLS0j+aMAAOOc+Sm4/v5+7dy5c+jr3bt3a9u2baqurtbUqVN100036e///u918skna/r06frmN7+ppqYmXXrppSO5bgDAOGceQFu2bNHnPve5oa9XrlwpSVq2bJnWrVunr33ta0omk7ruuuvU3d2t8847T88884w5qiSsrMJyi8OIGaJhwuFy0zpCYffonkLIFiOTNcSDxMts6y6OucfOFAq2mBJLBIokBYbtLDb+PdASsZLL5Uy9LeesdZ9YY4Es9ZbIFOm9XypdFde4R+tIUiTsfhdz4MABU29LdE9PT4+pd3mi0lZflXCutd1LSFlLFE/ePRJIkgqD7r2zBUMEl2OSkXkAzZs3T8GH5G+FQiF9+9vf1re//W1rawDAxwhZcAAALxhAAAAvGEAAAC8YQAAALxhAAAAvGEAAAC8YQAAALxhAAAAvGEAAAC8YQAAAL7x/HtCRZEJ5FUJugUKOsUOSpHTekGckKR24Z3xFjflemWzWuTbuuC8Oqahwz44LGdOpchlb3lTO8GtOcTxm6h2OuDdP9idNvWPGTDULS46ZZMu8CxnPlfd/gOSHKS21ZRK+23XQudb6uWD5vHu2X2DbJYrGbce+qrrKuTZpyN6TpGix+22ipMyW1Zc1xEBmDfvbFY+AAABeMIAAAF4wgAAAXjCAAABeMIAAAF4wgAAAXjCAAABeMIAAAF4wgAAAXjCAAABejNkonpRCKnIM2YmE3GMzIuW2uJyyhlr33vFiU+9EiXtsRtYY39GTc8/YiBojZ+IxW1xOrMi9PmKolaRIxD1GqNgYORQ2lIdsrZVODprqLVE8ZSWlpt7FZe71hYIhu0VScYn7uVWRs902+5Pu0UqRiC2LJ2KIeJKk4hL3237Y+Gt/YIoDs8UZWWKb+lIDzrUFx7Y8AgIAeMEAAgB4wQACAHjBAAIAeMEAAgB4wQACAHjBAAIAeMEAAgB4wQACAHjBAAIAeMEAAgB4MWaz4OKFIhU55hQVYu75R2ecc7ZpHXMWXuJcW15RYepdVuqewRU2ZDZJUjqTca7NGWolqcgYZhUtds/JKhTcc68kKRR23y9FkYipt3Lua0kP2rLdkn22bL+oIX8vWjx6eWDFxqwxyz63rEOSsrmsc208ZrurSw2658xJUsaQkxYrst1+yg1ZfdlMytQ7bsiB7O12PwdDjtmFPAICAHjBAAIAeMEAAgB4wQACAHjBAAIAeMEAAgB4wQACAHjBAAIAeMEAAgB4wQACAHgxZqN4IqGYcxTPYNg97qOo0haXUz9linNt9eTJpt4xQ7yKVSzuHplijUApKrKdNkEQuBcbfyUqhAz/wbaZyjvGiUhSLpcz9U6lbJEplige6/Gx7Jh83haVZNlO63kYN5zjRRHbiZVNG6OVervdi3O26KtCNu1ca7qtScpk3eOMiiKW88rtWPIICADgBQMIAOCFeQC9+OKLWrx4sZqamhQKhfT4448Pu/6aa65RKBQadlm4cOFIrRcAMEGYB1AymdTs2bO1Zs2aI9YsXLhQ7e3tQ5dHHnnkmBYJAJh4zC9CWLRokRYtWvShNfF4XA0NDU790um00uk//pGtt7fXuiQAwDg0Kn8D2rhxo+rq6jRz5kxdf/316urqOmLt6tWrlUgkhi7Nzc2jsSQAwBgz4gNo4cKF+uEPf6gNGzboH/7hH9TW1qZFixYd8SWtq1atUk9Pz9Bl7969I70kAMAYNOLvA7rqqquG/n3WWWdp1qxZOvHEE7Vx40ZddNFFH6iPx+Om1/MDACaGUX8Z9owZM1RbW6udO3eO9o8CAIwjoz6A3nrrLXV1damxsXG0fxQAYBwxPwXX398/7NHM7t27tW3bNlVXV6u6ulp33HGHli5dqoaGBu3atUtf+9rXdNJJJ2nBggUjunAAwPhmHkBbtmzR5z73uaGvV65cKUlatmyZ1q5dq+3bt+uhhx5Sd3e3mpqadMkll+jv/u7vzH/nScWLlHPMhsrGos593+nrt60j457bZM1hsuSHFQq2DC5rrpZFNOq+vyUpWuReX1TknusnSVnDPrfuw1ze/fhYaiWptKTUVF9eVu5ebDsNh70N4qMUldrWXVZW5lxrfQtGOOz+BI41Cy7Iue8TScqlBpxrB5O27Rwc6HOuteW1STlDtl9xSbGhr1uOonkAzZs370PvaJ999llrSwDAxxBZcAAALxhAAAAvGEAAAC8YQAAALxhAAAAvGEAAAC8YQAAALxhAAAAvGEAAAC8YQAAAL0b884BGSq5QkBzzzCon1zj3PX3OJ03rKEtUOtdac8xiUff6Qt4W8GXJ9wpHbNluki1TrRByrw9Ctn0YLhiy4Iz5XvnsoKF31tS7vNKQ7SapqNj9d8W+flveYdaSeZd23yeSlKhMONeWGbLGJKm/t8e5NijYsvqKi2Om+uSA+z4fNORLSlIh5H7swxHb7afMkNFpebSSdcy55BEQAMALBhAAwAsGEADACwYQAMALBhAAwAsGEADACwYQAMALBhAAwAsGEADACwYQAMCLMRvFEw69d3FRXVPt3Lex+QTTOkorytyLw7a4nFwu5VxbErcdqoghviNniGKRpCLHiKRDomH3tcSLbLFAocB9nw/kBky9g5x77EyRYX9LUiZtW0tv37vOtXljbFMk7B7fErjeKP9P78ED7uswxsiEA/fztpC3RSWVlRtu95LKDZFdyUHbWkqK3COK+o0xTNGo+3kbGA69ay2PgAAAXjCAAABeMIAAAF4wgAAAXjCAAABeMIAAAF4wgAAAXjCAAABeMIAAAF4wgAAAXjCAAABejNksuKAkqsAxX6s07p6VVByybXLIEKvV29tr6p1K9jnXVpTGTL1Li+POtbm0eyadJClqy+wKpdx/zykPTzL1zhkCqnKDtvy1dNI9VyuTtOWvJQdt+Xv5QsG5tqrKPZdMkiJxQ8hXPm/qHSstda49cMA9N06SBgfds/rSKds5nslkTPWTJ9c513Z19Zh6x2MlzrWWfSLZtjOTcc+wy+bczm8eAQEAvGAAAQC8YAABALxgAAEAvGAAAQC8YAABALxgAAEAvGAAAQC8YAABALxgAAEAvBizUTzhfEFhx4SQgXcOOvdN9yVN6+jtcY/NyOXdoyokqdIQU5LN2aJEOjq6nWt/v/t/Tb1zKfeIGkma1uQeUzKpqsrUu6K20bk2MEYOJbu6nGvf3muLkfnNjrdN9RlDBM5JJ0819T7t9JOdawezaVPvRsM5XmqolaQew22zqMh2V9fd7X6fIkl9fYZYrfIKU+9szj2GybwPD3ab6kcaj4AAAF6YBtDq1at19tlnq6KiQnV1dbr00ku1Y8eOYTWpVEqtra2qqalReXm5li5dqs7OzhFdNABg/DMNoLa2NrW2tmrz5s167rnnlM1mdckllyiZ/OPTWjfffLOefPJJPfbYY2pra9O+fft0+eWXj/jCAQDjm+mJ0WeeeWbY1+vWrVNdXZ22bt2qCy64QD09PXrggQf08MMP68ILL5QkPfjggzrttNO0efNmfeYznxm5lQMAxrVj+hvQoT8CVldXS5K2bt2qbDar+fPnD9Wceuqpmjp1qjZt2nTYHul0Wr29vcMuAICJ76gHUKFQ0E033aRzzz1XZ555piSpo6NDsVhMVe97JVN9fb06OjoO22f16tVKJBJDl+bm5qNdEgBgHDnqAdTa2qrXXntNjz766DEtYNWqVerp6Rm67N2795j6AQDGh6N6H9ANN9ygp556Si+++KKmTJky9P2GhgZlMhl1d3cPexTU2dmphoaGw/aKx+OKx90/PhoAMDGYHgEFQaAbbrhB69ev1wsvvKDp06cPu37OnDmKRqPasGHD0Pd27NihPXv2qKWlZWRWDACYEEyPgFpbW/Xwww/riSeeUEVFxdDfdRKJhEpKSpRIJHTttddq5cqVqq6uVmVlpW688Ua1tLTwCjgAwDCmAbR27VpJ0rx584Z9/8EHH9Q111wjSfrud7+rcDispUuXKp1Oa8GCBbrvvvtGZLEAgInDNICCIPjImuLiYq1Zs0Zr1qw56kVJUmywoKLQR/88SUp2GjK73nrLtI6yae5ZY9VVCVPv6ppJzrUHOveZegdh90N7oGfA1Hvry/9lql/0ufOca2PRmKl3Xu4ZbIW8LQsubsgPK2Qypt6/e+N/TPUHDG9PKEkUm3qf8akznGu7e93z1ySpOl3jXOty//L/C4UcwyJlz4IzM6y9osKWBReLuR/PXM6WR9nX474Py8os2ZU5pzqy4AAAXjCAAABeMIAAAF4wgAAAXjCAAABeMIAAAF4wgAAAXjCAAABeMIAAAF4wgAAAXoxyPsXRi4alqGNKRD5ScO7bn07aFhLknUuLY7bdGeTc41v6erptvQ2pJid/Ypqpd7r3XVN9LF7mXBsvtcUZ9Q26x+vUVrtHH0lSmfuy1ZB0PwclacGFnzXV9wy4n7d/cvYnTb1Li90/DuWdjj5T777u/c61Qch2+8lk08617oEz/6dgO54lho+UKRRsv/dHI+77JeQYgXNIWZl7zE/WcFsLh93ugHgEBADwggEEAPCCAQQA8IIBBADwggEEAPCCAQQA8IIBBADwggEEAPCCAQQA8IIBBADwggEEAPBizGbBRf7v4qIQuOc2FUejpnX09fQ41/YWx0y9B/vdazMZ99wrSSozrCUl94wnSTp15gxTfdyQNZY3/ko0aXKdc23t5HpT78E+9wNUCO0z9Z42bbKpPjHpZOfaeFmpqfdgf7dzbSxkCBmUNNhvyI4LG++OCu45jVljRlo+m7WtxRC+GI/a7id6unuda9ODA6bexSXut81Uv/vtIZ932988AgIAeMEAAgB4wQACAHjBAAIAeMEAAgB4wQACAHjBAAIAeMEAAgB4wQACAHjBAAIAeDF2o3hCIUVCbvOxOF7s3Lemutq2jrD7jG7v6DD1Lo277/7y0hJT72zWPZJj/zu2GJls3hbH0vwJ9+ieySc0m3qXlJQ71wZ598gmSYoYIlNq6xtMvd9u/19TfT7sHg0TidiOT9YQOZRKGvKjJEUdb8OSFC91P5aSFI24hnVJZcW220/PuwdN9YWC+z7PGmN+CgX38zaVtkV2Tap03+eJRMK5NuO4jTwCAgB4wQACAHjBAAIAeMEAAgB4wQACAHjBAAIAeMEAAgB4wQACAHjBAAIAeMEAAgB4wQACAHgxZrPg8tGIwo45UpMmu+e7lUxyzzOSpPIq9/pUX5+pdzTqPv/z+bypd7chyyoSipp6V9XVmeqr66Y514aLq0y9eweS7r0DW0ZauBByro3EbFljdY22zLsgyDnXZlK2cyWUd89Us+wTSTp44IBz7eSGuKm3Qu53X9kgY2ptvb1Z6kMR292uJTvOkl0pSfG4+z6Pht3Pk3SGLDgAwBhmGkCrV6/W2WefrYqKCtXV1enSSy/Vjh07htXMmzdPoVBo2GXFihUjumgAwPhnGkBtbW1qbW3V5s2b9dxzzymbzeqSSy5RMjn8aZDly5ervb196HLXXXeN6KIBAOOf6cnIZ555ZtjX69atU11dnbZu3aoLLrhg6PulpaVqaLB9PgoA4OPlmP4G1NPTI0mqft+HvP3oRz9SbW2tzjzzTK1atUoDA0f+cLR0Oq3e3t5hFwDAxHfUr4IrFAq66aabdO655+rMM88c+v4Xv/hFTZs2TU1NTdq+fbu+/vWva8eOHfrZz3522D6rV6/WHXfccbTLAACMU0c9gFpbW/Xaa6/pV7/61bDvX3fddUP/Puuss9TY2KiLLrpIu3bt0oknnviBPqtWrdLKlSuHvu7t7VVzs+0lqgCA8eeoBtANN9ygp556Si+++KKmTJnyobVz586VJO3cufOwAygej5teiw4AmBhMAygIAt14441av369Nm7cqOnTp3/k/9m2bZskqbGx8agWCACYmEwDqLW1VQ8//LCeeOIJVVRUqKOjQ5KUSCRUUlKiXbt26eGHH9bnP/951dTUaPv27br55pt1wQUXaNasWaOyAQCA8ck0gNauXSvpvTeb/v8efPBBXXPNNYrFYnr++ed17733KplMqrm5WUuXLtU3vvGNEVswAGBiMD8F92Gam5vV1tZ2TAs6JFwaU9gx1yhUGnPuOyhjTlZ/t3NtSdiWkxWJuGcrDSb7Tb0HB1LOtUWhYlPvyTUnmOonVTU51x48eOSX7B9OV8ce59qqykpT77IS93y3cNSWpxcLlZnqM4Pu+yWTHjT1Lo64b2ddjS0H8H9373Ku7e22vQWjps79vYb9H/JWkMMJGTPV3v9WlA+TydjugwbbO5xrbWmHtvugkiL3c7zIsS9ZcAAALxhAAAAvGEAAAC8YQAAALxhAAAAvGEAAAC8YQAAALxhAAAAvGEAAAC8YQAAAL47684BGWyyZUjTkNh8zXQed+2baO23riLiHW+RL3SNNJCmVM0Ry5G0xP4WM+7odd/OQiPG06etxjxH62frHTb0797zhXDupepKp92fO/axz7bTpnzD1zmZypvqQ3I9/PO4eTSVJ6YGkc23M+NEpiUm1zrV9A7YIocp8wbk2FLGdsyUl5ab6SZPcz6197e2m3rFi9wicQsg9WkeSug50OddGU2nn2kzW7fzmERAAwAsGEADACwYQAMALBhAAwAsGEADACwYQAMALBhAAwAsGEADACwYQAMALBhAAwAsGEADAizGbBZevqlI47DYfm2fNdG9cbdvkd3vfda59p92Q7SapvKTUubaxrt7UuxC4Z0KFI7Z8r1TWtp1v//73zrUv/PIFU+9I4J6pNpDZYeqdaGp2rp1ykuEclDSYdc8vlKT+gweca7PplKl3kMs415aUFJt6T5rsngW397e/M/XO7N3jXFtRWWnq3XPQdnwKuaxz7UB/r6l3KjXgXBs15gBGDJmEA2+/41ybybvdR/AICADgBQMIAOAFAwgA4AUDCADgBQMIAOAFAwgA4AUDCADgBQMIAOAFAwgA4AUDCADgxZiN4ikqLVFRxC1OprjcPdKmv88WgxEvdo+pCSlt6n3wYJdzbbjQZ+qdGTDE5aQqTL17337bVF/Iucd9/Mn0aabe23/3unPttIYTTL1nNLpH8QQp9ygWSQrnCqZ6GSJTUr39ttaDSefadNR2l3Ew5H6Od+7dZ+pdM7nOuba2apKp98ED+03173S0O9e63q8dMtDrfp9VGi039U4dcI8aKxxwX0ehQBQPAGAMYwABALxgAAEAvGAAAQC8YAABALxgAAEAvGAAAQC8YAABALxgAAEAvGAAAQC8YAABALwYs1lwtamcYuHAqbZz82/dG0+y5Z7FTnDPmyqrrjb17n3XPYPr7V0HTL2r48XOtbHB3abenYEtx6w4FnOuPa3Cfd2SVDd7tnNteSJh6l307kHn2nd3vGnqHQTu2W6S1PNOp3Nt5z5bplo4cM8NDIzHvnP/O8617ftt53ih3z17cXJlpal3SSxqqs9FQs61RUW2u93K0hLn2t633LPdJKl7117n2thAyrk273ie8AgIAOCFaQCtXbtWs2bNUmVlpSorK9XS0qKnn3566PpUKqXW1lbV1NSovLxcS5cuVWen+29uAICPD9MAmjJliu68805t3bpVW7Zs0YUXXqglS5bot7997ymwm2++WU8++aQee+wxtbW1ad++fbr88stHZeEAgPHN9GTk4sWLh339ne98R2vXrtXmzZs1ZcoUPfDAA3r44Yd14YUXSpIefPBBnXbaadq8ebM+85nPHLZnOp1WOv3H53J7DZ99AQAYv476b0D5fF6PPvqoksmkWlpatHXrVmWzWc2fP3+o5tRTT9XUqVO1adOmI/ZZvXq1EonE0KW52f1DwAAA45d5AP3mN79ReXm54vG4VqxYofXr1+v0009XR0eHYrGYqqqqhtXX19ero6PjiP1WrVqlnp6eocveve6vygAAjF/ml2HPnDlT27ZtU09Pj376059q2bJlamtrO+oFxONxxePuH3sNAJgYzAMoFovppJNOkiTNmTNHv/71r/W9731PV155pTKZjLq7u4c9Curs7FRDQ8OILRgAMDEc8/uACoWC0um05syZo2g0qg0bNgxdt2PHDu3Zs0ctLS3H+mMAABOM6RHQqlWrtGjRIk2dOlV9fX16+OGHtXHjRj377LNKJBK69tprtXLlSlVXV6uyslI33nijWlpajvgKOADAx5dpAO3fv19XX3212tvblUgkNGvWLD377LO6+OKLJUnf/e53FQ6HtXTpUqXTaS1YsED33XffUS0sFS1VIRxxqo3k3GMzOgbc4n0O6fmDezxI5R9sMRglBfcIlKKULQIlntnvXJvqd49LkexxLMmwe0xJKGp7Vjj0vhe9fJiuPbb4m76drzvXRottf8csKXOPV5Gk3KB77ExXe5ept+mJEEMsjCS9O9DtXFusrKl3auf/Ote+0el+e5Ck4voqU3006n4fVIjbYn7S+9zfzJ/faXvjf8JwXoUN91cZx/sI0639gQce+NDri4uLtWbNGq1Zs8bSFgDwMUQWHADACwYQAMALBhAAwAsGEADACwYQAMALBhAAwAsGEADACwYQAMALBhAAwAtzGvZoC4L3onIyhtiHiNyjXrJ591pJyuXdo3uyxnleZNjGIG+Lv0nn3WNnIgVbb2sUT95wfEKGfSJJobx7fdpQK0mBYR8Wcm6xUYeEsrbYmXzOfS0Z43ZKhngqwz6RpKxhLSHZ1p0puK+7yLhPQlnbdhYM53je+Gt/JmeIwDHelkOG23LYUHsoiufQ/fmRjLkB1NfXJ0l69PfbPa8EAHAs+vr6lEgkjnh9KPioEXWcFQoF7du3TxUVFQqF/vhbRW9vr5qbm7V3715VVlZ6XOHoYjsnjo/DNkps50QzEtsZBIH6+vrU1NSkcPjID/nG3COgcDisKVOmHPH6ysrKCX3wD2E7J46PwzZKbOdEc6zb+WGPfA7hRQgAAC8YQAAAL8bNAIrH47r99tsVj9s++Gu8YTsnjo/DNkps50RzPLdzzL0IAQDw8TBuHgEBACYWBhAAwAsGEADACwYQAMCLcTOA1qxZo0984hMqLi7W3Llz9d///d++lzSivvWtbykUCg27nHrqqb6XdUxefPFFLV68WE1NTQqFQnr88ceHXR8EgW677TY1NjaqpKRE8+fP15tvvulnscfgo7bzmmuu+cCxXbhwoZ/FHqXVq1fr7LPPVkVFherq6nTppZdqx44dw2pSqZRaW1tVU1Oj8vJyLV26VJ2dnZ5WfHRctnPevHkfOJ4rVqzwtOKjs3btWs2aNWvozaYtLS16+umnh64/XsdyXAygH//4x1q5cqVuv/12vfLKK5o9e7YWLFig/fv3+17aiDrjjDPU3t4+dPnVr37le0nHJJlMavbs2VqzZs1hr7/rrrv0/e9/X/fff79efvlllZWVacGCBUqlUsd5pcfmo7ZTkhYuXDjs2D7yyCPHcYXHrq2tTa2trdq8ebOee+45ZbNZXXLJJUomk0M1N998s5588kk99thjamtr0759+3T55Zd7XLWdy3ZK0vLly4cdz7vuusvTio/OlClTdOedd2rr1q3asmWLLrzwQi1ZskS//e1vJR3HYxmMA+ecc07Q2to69HU+nw+ampqC1atXe1zVyLr99tuD2bNn+17GqJEUrF+/fujrQqEQNDQ0BHfffffQ97q7u4N4PB488sgjHlY4Mt6/nUEQBMuWLQuWLFniZT2jZf/+/YGkoK2tLQiC945dNBoNHnvssaGa119/PZAUbNq0ydcyj9n7tzMIguBP//RPg6985Sv+FjVKJk2aFPzrv/7rcT2WY/4RUCaT0datWzV//vyh74XDYc2fP1+bNm3yuLKR9+abb6qpqUkzZszQl770Je3Zs8f3kkbN7t271dHRMey4JhIJzZ07d8IdV0nauHGj6urqNHPmTF1//fXq6uryvaRj0tPTI0mqrq6WJG3dulXZbHbY8Tz11FM1derUcX0837+dh/zoRz9SbW2tzjzzTK1atUoDAwM+ljci8vm8Hn30USWTSbW0tBzXYznmwkjf78CBA8rn86qvrx/2/fr6er3xxhueVjXy5s6dq3Xr1mnmzJlqb2/XHXfcofPPP1+vvfaaKioqfC9vxHV0dEjSYY/roesmioULF+ryyy/X9OnTtWvXLv3N3/yNFi1apE2bNikSsX2O0FhQKBR000036dxzz9WZZ54p6b3jGYvFVFVVNax2PB/Pw22nJH3xi1/UtGnT1NTUpO3bt+vrX/+6duzYoZ/97GceV2v3m9/8Ri0tLUqlUiovL9f69et1+umna9u2bcftWI75AfRxsWjRoqF/z5o1S3PnztW0adP0k5/8RNdee63HleFYXXXVVUP/PuusszRr1iydeOKJ2rhxoy666CKPKzs6ra2teu2118b93yg/ypG287rrrhv691lnnaXGxkZddNFF2rVrl0488cTjvcyjNnPmTG3btk09PT366U9/qmXLlqmtre24rmHMPwVXW1urSCTygVdgdHZ2qqGhwdOqRl9VVZVOOeUU7dy50/dSRsWhY/dxO66SNGPGDNXW1o7LY3vDDTfoqaee0i9/+cthH5vS0NCgTCaj7u7uYfXj9XgeaTsPZ+7cuZI07o5nLBbTSSedpDlz5mj16tWaPXu2vve97x3XYznmB1AsFtOcOXO0YcOGoe8VCgVt2LBBLS0tHlc2uvr7+7Vr1y41Njb6XsqomD59uhoaGoYd197eXr388ssT+rhK0ltvvaWurq5xdWyDINANN9yg9evX64UXXtD06dOHXT9nzhxFo9Fhx3PHjh3as2fPuDqeH7Wdh7Nt2zZJGlfH83AKhYLS6fTxPZYj+pKGUfLoo48G8Xg8WLduXfC73/0uuO6664Kqqqqgo6PD99JGzF//9V8HGzduDHbv3h289NJLwfz584Pa2tpg//79vpd21Pr6+oJXX301ePXVVwNJwT333BO8+uqrwR/+8IcgCILgzjvvDKqqqoInnngi2L59e7BkyZJg+vTpweDgoOeV23zYdvb19QVf/epXg02bNgW7d+8Onn/++eBTn/pUcPLJJwepVMr30p1df/31QSKRCDZu3Bi0t7cPXQYGBoZqVqxYEUydOjV44YUXgi1btgQtLS1BS0uLx1XbfdR27ty5M/j2t78dbNmyJdi9e3fwxBNPBDNmzAguuOACzyu3ufXWW4O2trZg9+7dwfbt24Nbb701CIVCwS9+8YsgCI7fsRwXAygIguAHP/hBMHXq1CAWiwXnnHNOsHnzZt9LGlFXXnll0NjYGMRiseCEE04IrrzyymDnzp2+l3VMfvnLXwaSPnBZtmxZEATvvRT7m9/8ZlBfXx/E4/HgoosuCnbs2OF30Ufhw7ZzYGAguOSSS4LJkycH0Wg0mDZtWrB8+fJx98vT4bZPUvDggw8O1QwODgZ/9Vd/FUyaNCkoLS0NLrvssqC9vd3foo/CR23nnj17ggsuuCCorq4O4vF4cNJJJwW33HJL0NPT43fhRn/5l38ZTJs2LYjFYsHkyZODiy66aGj4BMHxO5Z8HAMAwIsx/zcgAMDExAACAHjBAAIAeMEAAgB4wQACAHjBAAIAeMEAAgB4wQACAHjBAAJG0bx583TTTTf5XgYwJjGAAABeMIAAAF4wgIARkkwmdfXVV6u8vFyNjY36p3/6p2HXHzx4UFdffbUmTZqk0tJSLVq0SG+++eawmn/5l39Rc3OzSktLddlll+mee+75wCdTAhMFAwgYIbfccova2tr0xBNP6Be/+IU2btyoV155Zej6a665Rlu2bNF//Md/aNOmTQqCQJ///OeVzWYlSS+99JJWrFihr3zlK9q2bZsuvvhifec73/G1OcCoIw0bGAH9/f2qqanRv//7v+uKK66QJL377ruaMmWKrrvuOrW2tuqUU07RSy+9pM9+9rOSpK6uLjU3N+uhhx7SFVdcoauuukr9/f166qmnhvr+xV/8hZ566qkPfDolMBHwCAgYAbt27VImkxn6eGZJqq6u1syZMyVJr7/+uoqKioZdX1NTo5kzZ+r111+X9N6nTp5zzjnD+r7/a2AiYQABALxgAAEj4MQTT1Q0GtXLL7889L2DBw/qf/7nfyRJp512mnK53LDru7q6tGPHDp1++umSpJkzZ+rXv/71sL7v/xqYSIp8LwCYCMrLy3XttdfqlltuUU1Njerq6vS3f/u3Coff+x3v5JNP1pIlS7R8+XL98z//syoqKnTrrbfqhBNO0JIlSyRJN954oy644ALdc889Wrx4sV544QU9/fTTCoVCPjcNGDU8AgJGyN13363zzz9fixcv1vz583Xeeedpzpw5Q9c/+OCDmjNnjv7sz/5MLS0tCoJAP//5zxWNRiVJ5557ru6//37dc889mj17tp555hndfPPNKi4u9rVJwKjiVXDAGLZ8+XK98cYb+s///E/fSwFGHE/BAWPIP/7jP+riiy9WWVmZnn76aT300EO67777fC8LGBU8AgLGkD//8z/Xxo0b1dfXpxkzZujGG2/UihUrfC8LGBUMIACAF7wIAQDgBQMIAOAFAwgA4AUDCADgBQMIAOAFAwgA4AUDCADgBQMIAODF/wMT7bqdvQIddgAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will start by building the Convolutional Base."
      ],
      "metadata": {
        "id": "WsT5iysikviJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))"
      ],
      "metadata": {
        "id": "llgxzyZCkscF"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Layer 1\n",
        "\n",
        "The input shape of our data will be 32, 32, 3 and we will process 32 filters of size 3x3 over our input data. We will also apply the activation function relu to the output of each convolution operation.\n",
        "\n",
        "Layer 2\n",
        "\n",
        "This layer will perform the max pooling operation using 2x2 samples and a stride of 2.\n",
        "\n",
        "Other Layers\n",
        "\n",
        "The next set of layers do very similar things but take as input the feature map from the previous layer. They also increase the frequency of filters from 32 to 64. We can do this as our data shrinks in spacial dimensions as it passed through the layers, meaning we can afford (computationally) to add more depth."
      ],
      "metadata": {
        "id": "0fouaRtUlBVJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()  # let's have a look at our model so far"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mKR4Sn9lE0B",
        "outputId": "8fb27bc5-7d6b-4a64-eab0-fe69a4e950f5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 30, 30, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 15, 15, 32)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 13, 13, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 6, 6, 64)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 4, 4, 64)          36928     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 56320 (220.00 KB)\n",
            "Trainable params: 56320 (220.00 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adding Dense Layers\n",
        "\n",
        "So far, we have just completed the convolutional base. Now we need to take these extracted features and add a way to classify them. This is why we add the following layers to our model."
      ],
      "metadata": {
        "id": "yPOpmSVTlwaD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(10))"
      ],
      "metadata": {
        "id": "ZwHWj29Als95"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that the flatten layer changes the shape of our data so that we can feed it to the 64-node dense layer, follwed by the final output layer of 10 neurons (one for each class)."
      ],
      "metadata": {
        "id": "Uj_jXQ14l6Ei"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Training"
      ],
      "metadata": {
        "id": "a9J-THPJl98J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_images, train_labels, epochs=4,\n",
        "                    validation_data=(test_images, test_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e62rfcr4mDB6",
        "outputId": "3f9e30e4-fd30-49ef-c3fb-81cf66132612"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "1563/1563 [==============================] - 76s 48ms/step - loss: 1.5459 - accuracy: 0.4322 - val_loss: 1.3268 - val_accuracy: 0.5251\n",
            "Epoch 2/4\n",
            "1563/1563 [==============================] - 69s 44ms/step - loss: 1.1706 - accuracy: 0.5840 - val_loss: 1.0561 - val_accuracy: 0.6257\n",
            "Epoch 3/4\n",
            "1563/1563 [==============================] - 74s 47ms/step - loss: 1.0130 - accuracy: 0.6448 - val_loss: 0.9946 - val_accuracy: 0.6553\n",
            "Epoch 4/4\n",
            "1563/1563 [==============================] - 70s 45ms/step - loss: 0.9147 - accuracy: 0.6787 - val_loss: 0.9224 - val_accuracy: 0.6781\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluating the Model"
      ],
      "metadata": {
        "id": "JcRLtW9im34j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
        "print(test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7ksihyDm8Fb",
        "outputId": "d75e58d2-4abc-422c-c280-10a8b617b39a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 - 4s - loss: 0.9224 - accuracy: 0.6781 - 4s/epoch - 12ms/step\n",
            "0.6780999898910522\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Data Augmentation\n",
        "\n",
        "To avoid overfitting and create a larger dataset from a smaller one we can use a technique called data augmentation. This is simply performing random transofrmations on our images so that our model can generalize better. These transformations can be things like compressions, rotations, stretches and even color changes."
      ],
      "metadata": {
        "id": "VZnLrySfn0nN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# creates a data generator object that transforms images\n",
        "datagen = ImageDataGenerator(\n",
        "rotation_range=40,\n",
        "width_shift_range=0.2,\n",
        "height_shift_range=0.2,\n",
        "shear_range=0.2,\n",
        "zoom_range=0.2,\n",
        "horizontal_flip=True,\n",
        "fill_mode='nearest')\n",
        "\n",
        "# pick an image to transform\n",
        "test_img = train_images[1]\n",
        "img = image.img_to_array(test_img)  # convert image to numpy arry\n",
        "img = img.reshape((1,) + img.shape)  # reshape image\n",
        "\n",
        "i = 0\n",
        "\n",
        "for batch in datagen.flow(img, save_prefix='test', save_format='jpeg'):  # this loops runs forever until we break, saving images to current directory with specified prefix\n",
        "    plt.figure(i)\n",
        "    plot = plt.imshow(image.img_to_array(batch[0]))\n",
        "    i += 1\n",
        "    if i > 4:  # show 4 images\n",
        "        break\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "8uA-RHA_n6eD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using a Pretrained Model\n",
        "In this section we will combine the tecniques we learned above and use a pretrained model and fine tuning to classify images of dogs and cats using a small dataset."
      ],
      "metadata": {
        "id": "vzx2MjdlpI0C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Imports\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "keras = tf.keras"
      ],
      "metadata": {
        "id": "ZAVktyCApOjK"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset"
      ],
      "metadata": {
        "id": "qkKTR2Reppoa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_datasets as tfds\n",
        "tfds.disable_progress_bar()\n",
        "\n",
        "# split the data manually into 80% training, 10% testing, 10% validation\n",
        "(raw_train, raw_validation, raw_test), metadata = tfds.load(\n",
        "    'cats_vs_dogs',\n",
        "    split=['train[:80%]', 'train[80%:90%]', 'train[90%:]'],\n",
        "    with_info=True,\n",
        "    as_supervised=True,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9ddwN62pd3j",
        "outputId": "60ca4673-20f6-48d3-a46c-d81d5f05ea72"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading and preparing dataset 786.68 MiB (download: 786.68 MiB, generated: Unknown size, total: 786.68 MiB) to /root/tensorflow_datasets/cats_vs_dogs/4.0.0...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:1738 images were corrupted and were skipped\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset cats_vs_dogs downloaded and prepared to /root/tensorflow_datasets/cats_vs_dogs/4.0.0. Subsequent calls will reuse this data.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_label_name = metadata.features['label'].int2str  # creates a function object that we can use to get labels\n",
        "\n",
        "# display 2 images from the dataset\n",
        "for image, label in raw_train.take(5):\n",
        "  plt.figure()\n",
        "  plt.imshow(image)\n",
        "  plt.title(get_label_name(label))"
      ],
      "metadata": {
        "id": "J2_1tahVp9dJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Preprocessing\n",
        "\n",
        "Since the sizes of our images are all different, we need to convert them all to the same size."
      ],
      "metadata": {
        "id": "gBtCmzUBqPxK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SIZE = 160 # All images will be resized to 160x160\n",
        "\n",
        "def format_example(image, label):\n",
        "  \"\"\"\n",
        "  returns an image that is reshaped to IMG_SIZE\n",
        "  \"\"\"\n",
        "  image = tf.cast(image, tf.float32)\n",
        "  image = (image/127.5) - 1\n",
        "  image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))\n",
        "  return image, label"
      ],
      "metadata": {
        "id": "RFRmWetvqdGC"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can apply this function to all our images using .map()."
      ],
      "metadata": {
        "id": "dasd_9cCqrzi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = raw_train.map(format_example)\n",
        "validation = raw_validation.map(format_example)\n",
        "test = raw_test.map(format_example)"
      ],
      "metadata": {
        "id": "H6cMjRTyqq1C"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally we will shuffle and batch the images."
      ],
      "metadata": {
        "id": "_Hj4LMVbrCT6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32\n",
        "SHUFFLE_BUFFER_SIZE = 1000\n",
        "\n",
        "train_batches = train.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "validation_batches = validation.batch(BATCH_SIZE)\n",
        "test_batches = test.batch(BATCH_SIZE)"
      ],
      "metadata": {
        "id": "Peb9aP1drjrf"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Picking a Pretrained Model\n",
        "\n",
        "The model we are going to use as the convolutional base for our model is the MobileNet V2 developed at Google. This model is trained on 1.4 million images and has 1000 different classes.\n",
        "\n",
        "We want to use this model but only its convolutional base. So, when we load in the model, we'll specify that we don't want to load the top (classification) layer. We'll tell the model what input shape to expect and to use the predetermined weights from imagenet (Googles dataset).\n",
        "\n"
      ],
      "metadata": {
        "id": "1AX65N1Pru1p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SHAPE = (IMG_SIZE, IMG_SIZE, 3)\n",
        "\n",
        "# Create the base model from the pre-trained model MobileNet V2\n",
        "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n",
        "                                               include_top=False,\n",
        "                                               weights='imagenet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1FrZhUmryZX",
        "outputId": "6c1a0914-7192-4177-d56f-8776be8e3539"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_160_no_top.h5\n",
            "9406464/9406464 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7eDPJ4Ur3J-",
        "outputId": "37813c28-5ee3-460c-9782-ea0c41757390"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"mobilenetv2_1.00_160\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 160, 160, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " Conv1 (Conv2D)              (None, 80, 80, 32)           864       ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " bn_Conv1 (BatchNormalizati  (None, 80, 80, 32)           128       ['Conv1[0][0]']               \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " Conv1_relu (ReLU)           (None, 80, 80, 32)           0         ['bn_Conv1[0][0]']            \n",
            "                                                                                                  \n",
            " expanded_conv_depthwise (D  (None, 80, 80, 32)           288       ['Conv1_relu[0][0]']          \n",
            " epthwiseConv2D)                                                                                  \n",
            "                                                                                                  \n",
            " expanded_conv_depthwise_BN  (None, 80, 80, 32)           128       ['expanded_conv_depthwise[0][0\n",
            "  (BatchNormalization)                                              ]']                           \n",
            "                                                                                                  \n",
            " expanded_conv_depthwise_re  (None, 80, 80, 32)           0         ['expanded_conv_depthwise_BN[0\n",
            " lu (ReLU)                                                          ][0]']                        \n",
            "                                                                                                  \n",
            " expanded_conv_project (Con  (None, 80, 80, 16)           512       ['expanded_conv_depthwise_relu\n",
            " v2D)                                                               [0][0]']                      \n",
            "                                                                                                  \n",
            " expanded_conv_project_BN (  (None, 80, 80, 16)           64        ['expanded_conv_project[0][0]'\n",
            " BatchNormalization)                                                ]                             \n",
            "                                                                                                  \n",
            " block_1_expand (Conv2D)     (None, 80, 80, 96)           1536      ['expanded_conv_project_BN[0][\n",
            "                                                                    0]']                          \n",
            "                                                                                                  \n",
            " block_1_expand_BN (BatchNo  (None, 80, 80, 96)           384       ['block_1_expand[0][0]']      \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_1_expand_relu (ReLU)  (None, 80, 80, 96)           0         ['block_1_expand_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_1_pad (ZeroPadding2D  (None, 81, 81, 96)           0         ['block_1_expand_relu[0][0]'] \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block_1_depthwise (Depthwi  (None, 40, 40, 96)           864       ['block_1_pad[0][0]']         \n",
            " seConv2D)                                                                                        \n",
            "                                                                                                  \n",
            " block_1_depthwise_BN (Batc  (None, 40, 40, 96)           384       ['block_1_depthwise[0][0]']   \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " block_1_depthwise_relu (Re  (None, 40, 40, 96)           0         ['block_1_depthwise_BN[0][0]']\n",
            " LU)                                                                                              \n",
            "                                                                                                  \n",
            " block_1_project (Conv2D)    (None, 40, 40, 24)           2304      ['block_1_depthwise_relu[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " block_1_project_BN (BatchN  (None, 40, 40, 24)           96        ['block_1_project[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block_2_expand (Conv2D)     (None, 40, 40, 144)          3456      ['block_1_project_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_2_expand_BN (BatchNo  (None, 40, 40, 144)          576       ['block_2_expand[0][0]']      \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_2_expand_relu (ReLU)  (None, 40, 40, 144)          0         ['block_2_expand_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_2_depthwise (Depthwi  (None, 40, 40, 144)          1296      ['block_2_expand_relu[0][0]'] \n",
            " seConv2D)                                                                                        \n",
            "                                                                                                  \n",
            " block_2_depthwise_BN (Batc  (None, 40, 40, 144)          576       ['block_2_depthwise[0][0]']   \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " block_2_depthwise_relu (Re  (None, 40, 40, 144)          0         ['block_2_depthwise_BN[0][0]']\n",
            " LU)                                                                                              \n",
            "                                                                                                  \n",
            " block_2_project (Conv2D)    (None, 40, 40, 24)           3456      ['block_2_depthwise_relu[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " block_2_project_BN (BatchN  (None, 40, 40, 24)           96        ['block_2_project[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block_2_add (Add)           (None, 40, 40, 24)           0         ['block_1_project_BN[0][0]',  \n",
            "                                                                     'block_2_project_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_3_expand (Conv2D)     (None, 40, 40, 144)          3456      ['block_2_add[0][0]']         \n",
            "                                                                                                  \n",
            " block_3_expand_BN (BatchNo  (None, 40, 40, 144)          576       ['block_3_expand[0][0]']      \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_3_expand_relu (ReLU)  (None, 40, 40, 144)          0         ['block_3_expand_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_3_pad (ZeroPadding2D  (None, 41, 41, 144)          0         ['block_3_expand_relu[0][0]'] \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block_3_depthwise (Depthwi  (None, 20, 20, 144)          1296      ['block_3_pad[0][0]']         \n",
            " seConv2D)                                                                                        \n",
            "                                                                                                  \n",
            " block_3_depthwise_BN (Batc  (None, 20, 20, 144)          576       ['block_3_depthwise[0][0]']   \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " block_3_depthwise_relu (Re  (None, 20, 20, 144)          0         ['block_3_depthwise_BN[0][0]']\n",
            " LU)                                                                                              \n",
            "                                                                                                  \n",
            " block_3_project (Conv2D)    (None, 20, 20, 32)           4608      ['block_3_depthwise_relu[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " block_3_project_BN (BatchN  (None, 20, 20, 32)           128       ['block_3_project[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block_4_expand (Conv2D)     (None, 20, 20, 192)          6144      ['block_3_project_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_4_expand_BN (BatchNo  (None, 20, 20, 192)          768       ['block_4_expand[0][0]']      \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_4_expand_relu (ReLU)  (None, 20, 20, 192)          0         ['block_4_expand_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_4_depthwise (Depthwi  (None, 20, 20, 192)          1728      ['block_4_expand_relu[0][0]'] \n",
            " seConv2D)                                                                                        \n",
            "                                                                                                  \n",
            " block_4_depthwise_BN (Batc  (None, 20, 20, 192)          768       ['block_4_depthwise[0][0]']   \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " block_4_depthwise_relu (Re  (None, 20, 20, 192)          0         ['block_4_depthwise_BN[0][0]']\n",
            " LU)                                                                                              \n",
            "                                                                                                  \n",
            " block_4_project (Conv2D)    (None, 20, 20, 32)           6144      ['block_4_depthwise_relu[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " block_4_project_BN (BatchN  (None, 20, 20, 32)           128       ['block_4_project[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block_4_add (Add)           (None, 20, 20, 32)           0         ['block_3_project_BN[0][0]',  \n",
            "                                                                     'block_4_project_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_5_expand (Conv2D)     (None, 20, 20, 192)          6144      ['block_4_add[0][0]']         \n",
            "                                                                                                  \n",
            " block_5_expand_BN (BatchNo  (None, 20, 20, 192)          768       ['block_5_expand[0][0]']      \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_5_expand_relu (ReLU)  (None, 20, 20, 192)          0         ['block_5_expand_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_5_depthwise (Depthwi  (None, 20, 20, 192)          1728      ['block_5_expand_relu[0][0]'] \n",
            " seConv2D)                                                                                        \n",
            "                                                                                                  \n",
            " block_5_depthwise_BN (Batc  (None, 20, 20, 192)          768       ['block_5_depthwise[0][0]']   \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " block_5_depthwise_relu (Re  (None, 20, 20, 192)          0         ['block_5_depthwise_BN[0][0]']\n",
            " LU)                                                                                              \n",
            "                                                                                                  \n",
            " block_5_project (Conv2D)    (None, 20, 20, 32)           6144      ['block_5_depthwise_relu[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " block_5_project_BN (BatchN  (None, 20, 20, 32)           128       ['block_5_project[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block_5_add (Add)           (None, 20, 20, 32)           0         ['block_4_add[0][0]',         \n",
            "                                                                     'block_5_project_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_6_expand (Conv2D)     (None, 20, 20, 192)          6144      ['block_5_add[0][0]']         \n",
            "                                                                                                  \n",
            " block_6_expand_BN (BatchNo  (None, 20, 20, 192)          768       ['block_6_expand[0][0]']      \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_6_expand_relu (ReLU)  (None, 20, 20, 192)          0         ['block_6_expand_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_6_pad (ZeroPadding2D  (None, 21, 21, 192)          0         ['block_6_expand_relu[0][0]'] \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block_6_depthwise (Depthwi  (None, 10, 10, 192)          1728      ['block_6_pad[0][0]']         \n",
            " seConv2D)                                                                                        \n",
            "                                                                                                  \n",
            " block_6_depthwise_BN (Batc  (None, 10, 10, 192)          768       ['block_6_depthwise[0][0]']   \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " block_6_depthwise_relu (Re  (None, 10, 10, 192)          0         ['block_6_depthwise_BN[0][0]']\n",
            " LU)                                                                                              \n",
            "                                                                                                  \n",
            " block_6_project (Conv2D)    (None, 10, 10, 64)           12288     ['block_6_depthwise_relu[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " block_6_project_BN (BatchN  (None, 10, 10, 64)           256       ['block_6_project[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block_7_expand (Conv2D)     (None, 10, 10, 384)          24576     ['block_6_project_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_7_expand_BN (BatchNo  (None, 10, 10, 384)          1536      ['block_7_expand[0][0]']      \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_7_expand_relu (ReLU)  (None, 10, 10, 384)          0         ['block_7_expand_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_7_depthwise (Depthwi  (None, 10, 10, 384)          3456      ['block_7_expand_relu[0][0]'] \n",
            " seConv2D)                                                                                        \n",
            "                                                                                                  \n",
            " block_7_depthwise_BN (Batc  (None, 10, 10, 384)          1536      ['block_7_depthwise[0][0]']   \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " block_7_depthwise_relu (Re  (None, 10, 10, 384)          0         ['block_7_depthwise_BN[0][0]']\n",
            " LU)                                                                                              \n",
            "                                                                                                  \n",
            " block_7_project (Conv2D)    (None, 10, 10, 64)           24576     ['block_7_depthwise_relu[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " block_7_project_BN (BatchN  (None, 10, 10, 64)           256       ['block_7_project[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block_7_add (Add)           (None, 10, 10, 64)           0         ['block_6_project_BN[0][0]',  \n",
            "                                                                     'block_7_project_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_8_expand (Conv2D)     (None, 10, 10, 384)          24576     ['block_7_add[0][0]']         \n",
            "                                                                                                  \n",
            " block_8_expand_BN (BatchNo  (None, 10, 10, 384)          1536      ['block_8_expand[0][0]']      \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_8_expand_relu (ReLU)  (None, 10, 10, 384)          0         ['block_8_expand_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_8_depthwise (Depthwi  (None, 10, 10, 384)          3456      ['block_8_expand_relu[0][0]'] \n",
            " seConv2D)                                                                                        \n",
            "                                                                                                  \n",
            " block_8_depthwise_BN (Batc  (None, 10, 10, 384)          1536      ['block_8_depthwise[0][0]']   \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " block_8_depthwise_relu (Re  (None, 10, 10, 384)          0         ['block_8_depthwise_BN[0][0]']\n",
            " LU)                                                                                              \n",
            "                                                                                                  \n",
            " block_8_project (Conv2D)    (None, 10, 10, 64)           24576     ['block_8_depthwise_relu[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " block_8_project_BN (BatchN  (None, 10, 10, 64)           256       ['block_8_project[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block_8_add (Add)           (None, 10, 10, 64)           0         ['block_7_add[0][0]',         \n",
            "                                                                     'block_8_project_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_9_expand (Conv2D)     (None, 10, 10, 384)          24576     ['block_8_add[0][0]']         \n",
            "                                                                                                  \n",
            " block_9_expand_BN (BatchNo  (None, 10, 10, 384)          1536      ['block_9_expand[0][0]']      \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_9_expand_relu (ReLU)  (None, 10, 10, 384)          0         ['block_9_expand_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_9_depthwise (Depthwi  (None, 10, 10, 384)          3456      ['block_9_expand_relu[0][0]'] \n",
            " seConv2D)                                                                                        \n",
            "                                                                                                  \n",
            " block_9_depthwise_BN (Batc  (None, 10, 10, 384)          1536      ['block_9_depthwise[0][0]']   \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " block_9_depthwise_relu (Re  (None, 10, 10, 384)          0         ['block_9_depthwise_BN[0][0]']\n",
            " LU)                                                                                              \n",
            "                                                                                                  \n",
            " block_9_project (Conv2D)    (None, 10, 10, 64)           24576     ['block_9_depthwise_relu[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " block_9_project_BN (BatchN  (None, 10, 10, 64)           256       ['block_9_project[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block_9_add (Add)           (None, 10, 10, 64)           0         ['block_8_add[0][0]',         \n",
            "                                                                     'block_9_project_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_10_expand (Conv2D)    (None, 10, 10, 384)          24576     ['block_9_add[0][0]']         \n",
            "                                                                                                  \n",
            " block_10_expand_BN (BatchN  (None, 10, 10, 384)          1536      ['block_10_expand[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block_10_expand_relu (ReLU  (None, 10, 10, 384)          0         ['block_10_expand_BN[0][0]']  \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block_10_depthwise (Depthw  (None, 10, 10, 384)          3456      ['block_10_expand_relu[0][0]']\n",
            " iseConv2D)                                                                                       \n",
            "                                                                                                  \n",
            " block_10_depthwise_BN (Bat  (None, 10, 10, 384)          1536      ['block_10_depthwise[0][0]']  \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " block_10_depthwise_relu (R  (None, 10, 10, 384)          0         ['block_10_depthwise_BN[0][0]'\n",
            " eLU)                                                               ]                             \n",
            "                                                                                                  \n",
            " block_10_project (Conv2D)   (None, 10, 10, 96)           36864     ['block_10_depthwise_relu[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " block_10_project_BN (Batch  (None, 10, 10, 96)           384       ['block_10_project[0][0]']    \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " block_11_expand (Conv2D)    (None, 10, 10, 576)          55296     ['block_10_project_BN[0][0]'] \n",
            "                                                                                                  \n",
            " block_11_expand_BN (BatchN  (None, 10, 10, 576)          2304      ['block_11_expand[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block_11_expand_relu (ReLU  (None, 10, 10, 576)          0         ['block_11_expand_BN[0][0]']  \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block_11_depthwise (Depthw  (None, 10, 10, 576)          5184      ['block_11_expand_relu[0][0]']\n",
            " iseConv2D)                                                                                       \n",
            "                                                                                                  \n",
            " block_11_depthwise_BN (Bat  (None, 10, 10, 576)          2304      ['block_11_depthwise[0][0]']  \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " block_11_depthwise_relu (R  (None, 10, 10, 576)          0         ['block_11_depthwise_BN[0][0]'\n",
            " eLU)                                                               ]                             \n",
            "                                                                                                  \n",
            " block_11_project (Conv2D)   (None, 10, 10, 96)           55296     ['block_11_depthwise_relu[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " block_11_project_BN (Batch  (None, 10, 10, 96)           384       ['block_11_project[0][0]']    \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " block_11_add (Add)          (None, 10, 10, 96)           0         ['block_10_project_BN[0][0]', \n",
            "                                                                     'block_11_project_BN[0][0]'] \n",
            "                                                                                                  \n",
            " block_12_expand (Conv2D)    (None, 10, 10, 576)          55296     ['block_11_add[0][0]']        \n",
            "                                                                                                  \n",
            " block_12_expand_BN (BatchN  (None, 10, 10, 576)          2304      ['block_12_expand[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block_12_expand_relu (ReLU  (None, 10, 10, 576)          0         ['block_12_expand_BN[0][0]']  \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block_12_depthwise (Depthw  (None, 10, 10, 576)          5184      ['block_12_expand_relu[0][0]']\n",
            " iseConv2D)                                                                                       \n",
            "                                                                                                  \n",
            " block_12_depthwise_BN (Bat  (None, 10, 10, 576)          2304      ['block_12_depthwise[0][0]']  \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " block_12_depthwise_relu (R  (None, 10, 10, 576)          0         ['block_12_depthwise_BN[0][0]'\n",
            " eLU)                                                               ]                             \n",
            "                                                                                                  \n",
            " block_12_project (Conv2D)   (None, 10, 10, 96)           55296     ['block_12_depthwise_relu[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " block_12_project_BN (Batch  (None, 10, 10, 96)           384       ['block_12_project[0][0]']    \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " block_12_add (Add)          (None, 10, 10, 96)           0         ['block_11_add[0][0]',        \n",
            "                                                                     'block_12_project_BN[0][0]'] \n",
            "                                                                                                  \n",
            " block_13_expand (Conv2D)    (None, 10, 10, 576)          55296     ['block_12_add[0][0]']        \n",
            "                                                                                                  \n",
            " block_13_expand_BN (BatchN  (None, 10, 10, 576)          2304      ['block_13_expand[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block_13_expand_relu (ReLU  (None, 10, 10, 576)          0         ['block_13_expand_BN[0][0]']  \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block_13_pad (ZeroPadding2  (None, 11, 11, 576)          0         ['block_13_expand_relu[0][0]']\n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " block_13_depthwise (Depthw  (None, 5, 5, 576)            5184      ['block_13_pad[0][0]']        \n",
            " iseConv2D)                                                                                       \n",
            "                                                                                                  \n",
            " block_13_depthwise_BN (Bat  (None, 5, 5, 576)            2304      ['block_13_depthwise[0][0]']  \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " block_13_depthwise_relu (R  (None, 5, 5, 576)            0         ['block_13_depthwise_BN[0][0]'\n",
            " eLU)                                                               ]                             \n",
            "                                                                                                  \n",
            " block_13_project (Conv2D)   (None, 5, 5, 160)            92160     ['block_13_depthwise_relu[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " block_13_project_BN (Batch  (None, 5, 5, 160)            640       ['block_13_project[0][0]']    \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " block_14_expand (Conv2D)    (None, 5, 5, 960)            153600    ['block_13_project_BN[0][0]'] \n",
            "                                                                                                  \n",
            " block_14_expand_BN (BatchN  (None, 5, 5, 960)            3840      ['block_14_expand[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block_14_expand_relu (ReLU  (None, 5, 5, 960)            0         ['block_14_expand_BN[0][0]']  \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block_14_depthwise (Depthw  (None, 5, 5, 960)            8640      ['block_14_expand_relu[0][0]']\n",
            " iseConv2D)                                                                                       \n",
            "                                                                                                  \n",
            " block_14_depthwise_BN (Bat  (None, 5, 5, 960)            3840      ['block_14_depthwise[0][0]']  \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " block_14_depthwise_relu (R  (None, 5, 5, 960)            0         ['block_14_depthwise_BN[0][0]'\n",
            " eLU)                                                               ]                             \n",
            "                                                                                                  \n",
            " block_14_project (Conv2D)   (None, 5, 5, 160)            153600    ['block_14_depthwise_relu[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " block_14_project_BN (Batch  (None, 5, 5, 160)            640       ['block_14_project[0][0]']    \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " block_14_add (Add)          (None, 5, 5, 160)            0         ['block_13_project_BN[0][0]', \n",
            "                                                                     'block_14_project_BN[0][0]'] \n",
            "                                                                                                  \n",
            " block_15_expand (Conv2D)    (None, 5, 5, 960)            153600    ['block_14_add[0][0]']        \n",
            "                                                                                                  \n",
            " block_15_expand_BN (BatchN  (None, 5, 5, 960)            3840      ['block_15_expand[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block_15_expand_relu (ReLU  (None, 5, 5, 960)            0         ['block_15_expand_BN[0][0]']  \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block_15_depthwise (Depthw  (None, 5, 5, 960)            8640      ['block_15_expand_relu[0][0]']\n",
            " iseConv2D)                                                                                       \n",
            "                                                                                                  \n",
            " block_15_depthwise_BN (Bat  (None, 5, 5, 960)            3840      ['block_15_depthwise[0][0]']  \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " block_15_depthwise_relu (R  (None, 5, 5, 960)            0         ['block_15_depthwise_BN[0][0]'\n",
            " eLU)                                                               ]                             \n",
            "                                                                                                  \n",
            " block_15_project (Conv2D)   (None, 5, 5, 160)            153600    ['block_15_depthwise_relu[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " block_15_project_BN (Batch  (None, 5, 5, 160)            640       ['block_15_project[0][0]']    \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " block_15_add (Add)          (None, 5, 5, 160)            0         ['block_14_add[0][0]',        \n",
            "                                                                     'block_15_project_BN[0][0]'] \n",
            "                                                                                                  \n",
            " block_16_expand (Conv2D)    (None, 5, 5, 960)            153600    ['block_15_add[0][0]']        \n",
            "                                                                                                  \n",
            " block_16_expand_BN (BatchN  (None, 5, 5, 960)            3840      ['block_16_expand[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " block_16_expand_relu (ReLU  (None, 5, 5, 960)            0         ['block_16_expand_BN[0][0]']  \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " block_16_depthwise (Depthw  (None, 5, 5, 960)            8640      ['block_16_expand_relu[0][0]']\n",
            " iseConv2D)                                                                                       \n",
            "                                                                                                  \n",
            " block_16_depthwise_BN (Bat  (None, 5, 5, 960)            3840      ['block_16_depthwise[0][0]']  \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " block_16_depthwise_relu (R  (None, 5, 5, 960)            0         ['block_16_depthwise_BN[0][0]'\n",
            " eLU)                                                               ]                             \n",
            "                                                                                                  \n",
            " block_16_project (Conv2D)   (None, 5, 5, 320)            307200    ['block_16_depthwise_relu[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " block_16_project_BN (Batch  (None, 5, 5, 320)            1280      ['block_16_project[0][0]']    \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " Conv_1 (Conv2D)             (None, 5, 5, 1280)           409600    ['block_16_project_BN[0][0]'] \n",
            "                                                                                                  \n",
            " Conv_1_bn (BatchNormalizat  (None, 5, 5, 1280)           5120      ['Conv_1[0][0]']              \n",
            " ion)                                                                                             \n",
            "                                                                                                  \n",
            " out_relu (ReLU)             (None, 5, 5, 1280)           0         ['Conv_1_bn[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2257984 (8.61 MB)\n",
            "Trainable params: 2223872 (8.48 MB)\n",
            "Non-trainable params: 34112 (133.25 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "At this point this base_model will simply output a shape (32, 5, 5, 1280) tensor that is a feature extraction from our original (1, 160, 160, 3) image. The 32 means that we have 32 layers of differnt filters/features."
      ],
      "metadata": {
        "id": "-IrzIaOrsYrj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for image, _ in train_batches.take(1):\n",
        "   pass\n",
        "\n",
        "feature_batch = base_model(image)\n",
        "print(feature_batch.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0qCfIctscEi",
        "outputId": "7b21ec0d-21ce-4cef-f977-7889fda4ab73"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32, 5, 5, 1280)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Freezing the Base\n",
        "\n",
        "The term freezing refers to disabling the training property of a layer. It simply means we won’t make any changes to the weights of any layers that are frozen during training. This is important as we don't want to change the convolutional base that already has learned weights."
      ],
      "metadata": {
        "id": "M1FzsJvZshVs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model.trainable = False"
      ],
      "metadata": {
        "id": "HUOOoQVVskcH"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adding our Classifier\n",
        "Now that we have our base layer setup, we can add the classifier. Instead of flattening the feature map of the base layer we will use a global average pooling layer that will average the entire 5x5 area of each 2D feature map and return to us a single 1280 element vector per filter."
      ],
      "metadata": {
        "id": "NPxMmG4VsrsL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()"
      ],
      "metadata": {
        "id": "cvDXmXJRsuNY"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we will add the predicition layer that will be a single dense neuron. We can do this because we only have two classes to predict for."
      ],
      "metadata": {
        "id": "3C_ro5ZVs0y5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prediction_layer = keras.layers.Dense(1)"
      ],
      "metadata": {
        "id": "Bv97iksGs2Yj"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will combine these layers together in a model."
      ],
      "metadata": {
        "id": "L2IjFsyJs6z3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "  base_model,\n",
        "  global_average_layer,\n",
        "  prediction_layer\n",
        "])"
      ],
      "metadata": {
        "id": "LaeSUE3JtA6f"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training the Model"
      ],
      "metadata": {
        "id": "h9u2C6TRtdLi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_learning_rate = 0.0001\n",
        "model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=base_learning_rate),\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oz0ETXw-tfnC",
        "outputId": "9a17336c-8994-4255-8145-8ea377f63c40"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We can evaluate the model right now to see how it does before training it on our new images\n",
        "initial_epochs = 3\n",
        "validation_steps=20\n",
        "\n",
        "loss0,accuracy0 = model.evaluate(validation_batches, steps = validation_steps)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pbll6foCtlyl",
        "outputId": "60a4e636-6f84-4ea0-961c-6a312cd66338"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 [==============================] - 15s 665ms/step - loss: 0.9664 - accuracy: 0.4594\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now we can train it on our images\n",
        "history = model.fit(train_batches,\n",
        "                    epochs=initial_epochs,\n",
        "                    validation_data=validation_batches)\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "print(acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bAPsStj3tvN_",
        "outputId": "33505447-4ad0-449d-c2f7-2ea401907dee"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "582/582 [==============================] - 365s 619ms/step - loss: 0.0742 - accuracy: 0.9704 - val_loss: 0.0505 - val_accuracy: 0.9789\n",
            "Epoch 2/3\n",
            "582/582 [==============================] - 359s 613ms/step - loss: 0.0437 - accuracy: 0.9837 - val_loss: 0.0449 - val_accuracy: 0.9850\n",
            "Epoch 3/3\n",
            "582/582 [==============================] - 366s 626ms/step - loss: 0.0397 - accuracy: 0.9856 - val_loss: 0.0426 - val_accuracy: 0.9854\n",
            "[0.9703922867774963, 0.9837184548377991, 0.985599160194397]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"dogs_vs_cats.h5\")  # we can save the model and reload it at anytime in the future\n",
        "new_model = tf.keras.models.load_model('dogs_vs_cats.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KokWbTtNulXo",
        "outputId": "28c216cd-6741-4659-cd89-2d6e8a25fe48"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Object Detection\n",
        "\n",
        "https://github.com/tensorflow/models/tree/master/research/object_detection"
      ],
      "metadata": {
        "id": "H3j7vVadvSo9"
      }
    }
  ]
}